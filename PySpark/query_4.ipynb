{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2083285-2c12-4d58-83a3-bd8ab7626ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>3077</td><td>application_1732639283265_3033</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3033/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-166.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3033_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '8g', 'spark.executor.cores': '4'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>2944</td><td>application_1732639283265_2903</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2903/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-166.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2903_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>2966</td><td>application_1732639283265_2924</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2924/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2924_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>2971</td><td>application_1732639283265_2929</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2929/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-166.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2929_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>2975</td><td>application_1732639283265_2933</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2933/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-94.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2933_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>2976</td><td>application_1732639283265_2934</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2934/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-203.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2934_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3000</td><td>application_1732639283265_2958</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2958/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-233.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2958_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3005</td><td>application_1732639283265_2963</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2963/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-233.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2963_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3010</td><td>application_1732639283265_2968</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2968/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-193.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2968_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3017</td><td>application_1732639283265_2975</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2975/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-119.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2975_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3019</td><td>application_1732639283265_2977</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2977/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-112.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2977_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3021</td><td>application_1732639283265_2979</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2979/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-203.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2979_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3028</td><td>application_1732639283265_2986</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2986/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-193.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2986_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3029</td><td>application_1732639283265_2987</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2987/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-203.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2987_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3035</td><td>application_1732639283265_2993</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2993/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-178.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2993_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3041</td><td>application_1732639283265_2999</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_2999/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-227.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_2999_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3044</td><td>application_1732639283265_3002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3002_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3046</td><td>application_1732639283265_3004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3004/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-227.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3004_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3052</td><td>application_1732639283265_3010</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3010/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-193.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3010_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3060</td><td>application_1732639283265_3018</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3018/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-166.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3018_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3064</td><td>application_1732639283265_3021</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3021/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-203.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3021_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3070</td><td>application_1732639283265_3026</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3026/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-94.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3026_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3071</td><td>application_1732639283265_3027</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3027/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-203.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3027_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3072</td><td>application_1732639283265_3028</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3028/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-227.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3028_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3075</td><td>application_1732639283265_3031</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3031/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-16.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3031_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>3077</td><td>application_1732639283265_3033</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-36.eu-central-1.compute.internal:20888/proxy/application_1732639283265_3033/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-166.eu-central-1.compute.internal:8042/node/containerlogs/container_1732639283265_3033_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"8g\",\n",
    "        \"spark.executor.cores\": \"4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02599ec5-f185-4eed-9663-d8d92630eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor Instances: 2\n",
      "Executor Memory: 8g\n",
      "Executor Cores: 4\n",
      "Top 3:\n",
      "+--------------------+---+\n",
      "|      Victim Descent|  #|\n",
      "+--------------------+---+\n",
      "|               White|649|\n",
      "|               Other| 72|\n",
      "|Hispanic/Latin/Me...| 66|\n",
      "|             Unknown| 38|\n",
      "|               Black| 37|\n",
      "|         Other Asian| 21|\n",
      "|American Indian/A...|  1|\n",
      "|             Chinese|  1|\n",
      "+--------------------+---+\n",
      "\n",
      "Bottom 3:\n",
      "+--------------------+----+\n",
      "|      Victim Descent|   #|\n",
      "+--------------------+----+\n",
      "|Hispanic/Latin/Me...|2815|\n",
      "|               Black| 761|\n",
      "|               White| 330|\n",
      "|               Other| 187|\n",
      "|         Other Asian| 113|\n",
      "|             Unknown|  22|\n",
      "|American Indian/A...|  21|\n",
      "|              Korean|   5|\n",
      "|             Chinese|   3|\n",
      "|         AsianIndian|   1|\n",
      "|            Filipino|   1|\n",
      "+--------------------+----+\n",
      "\n",
      "Execution Time:  60.674782514572144"
     ]
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import col, sum, regexp_replace, substring, udf, count\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "\n",
    "# Create spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Q4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "conf = spark.sparkContext.getConf()\n",
    "\n",
    "# Print relevant executor settings\n",
    "print(\"Executor Instances:\", conf.get(\"spark.executor.instances\"))\n",
    "print(\"Executor Memory:\", conf.get(\"spark.executor.memory\"))\n",
    "print(\"Executor Cores:\", conf.get(\"spark.executor.cores\"))\n",
    "\n",
    "\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "\n",
    "# Create sedona context\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Read the file from s3\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/2010_Census_Blocks.geojson\"\n",
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "# Formatting magic\n",
    "flattened_df = blocks_df.select( \\\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \\\n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "\n",
    "#flattened_df.printSchema()\n",
    "\n",
    "#select only desired columns from 2010_Census_Blocks.geojson, filter data only from LA, keep only valid data and then do summations for Housing and Population and create geometry\n",
    "group_flattened = (\n",
    "    flattened_df\n",
    "    .select(\"COMM\", \"POP_2010\", \"ZCTA10\", \"CITY\", \"HOUSING10\", \"geometry\")\n",
    "    .filter(\n",
    "        (col(\"CITY\") == \"Los Angeles\") &\n",
    "        (col(\"ZCTA10\") > 0) &\n",
    "        (col(\"HOUSING10\") > 0) &\n",
    "        (col(\"POP_2010\") > 0) &\n",
    "        (col(\"COMM\") != \"\")\n",
    "    )\n",
    "    .groupBy(\"COMM\", \"ZCTA10\")\n",
    "    .agg(\n",
    "        sum(\"POP_2010\").alias(\"Total_POP\"),\n",
    "        sum(\"HOUSING10\").alias(\"Total_Housing\"),\n",
    "        ST_Union_Aggr(\"geometry\").alias(\"geometry\")\n",
    "    )\n",
    ")\n",
    "\n",
    "#group_flattened.show()\n",
    "\n",
    "median_housing_income = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/LA_income_2015.csv\", header=True, inferSchema=True)\n",
    "#median_housing_income.show()\n",
    "\n",
    "#join Cencus with median house income. Join key is Zip Code. Result is GDP Per Capita in every area.\n",
    "joined = (\n",
    "    group_flattened\n",
    "    .join(median_housing_income, group_flattened[\"ZCTA10\"] == median_housing_income[\"Zip Code\"])\n",
    "    .withColumn(\n",
    "        \"Estimated Median Income\", \n",
    "        regexp_replace(col(\"Estimated Median Income\"), \"[^0-9]\", \"\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"ZIP_Total_Income\", \n",
    "        (col(\"Estimated Median Income\") * col(\"Total_Housing\"))\n",
    "    )\n",
    "    .groupBy(\"COMM\")\n",
    "    .agg(\n",
    "        sum(\"Total_POP\").alias(\"Total_COMM_Pop\"),\n",
    "        sum(\"ZIP_Total_Income\").alias(\"COMM_Total_Income\"),\n",
    "        ST_Union_Aggr(\"geometry\").alias(\"geometry\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"GDP_Per_Capita\",\n",
    "        (col(\"COMM_Total_Income\")/col(\"Total_COMM_Pop\"))\n",
    "    )\n",
    "    .select(\"COMM\", \"GDP_Per_Capita\", \"geometry\") \n",
    ")\n",
    "\n",
    "#joined.show()\n",
    "\n",
    "top_3 = joined.orderBy(col(\"GDP_Per_Capita\"), ascending=False).limit(3)\n",
    "\n",
    "bottom_3 = joined.orderBy(col(\"GDP_Per_Capita\"), ascending=True).limit(3)\n",
    "\n",
    "#print(\"Top 3 by GDP_Per_Capita:\")\n",
    "#top_3.show()\n",
    "\n",
    "#print(\"Bottom 3 by GDP_Per_Capita:\")\n",
    "#bottom_3.show()\n",
    "\n",
    "crime_data_csv = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "crime_data_df = spark.read.csv(crime_data_csv, header=True, inferSchema=True)\n",
    "\n",
    "#keep crime data only from 2015 and and Victim Descent is mentioned. Also create a geometry column according to longtitude and latitude columns \n",
    "crime_data_df_2015 = (\n",
    "    crime_data_df\n",
    "    .filter(\n",
    "        (substring(col(\"DATE OCC\"), 7, 4) == \"2015\") &\n",
    "        (col(\"Vict Descent\") != \"\")\n",
    "    )\n",
    "    .select(\"DATE OCC\", \"LAT\", \"LON\", \"Vict Descent\")\n",
    "    .withColumn(\"geom\", ST_Point(\"LON\", \"LAT\"))\n",
    "    .drop(\"LAT\", \"LON\")\n",
    ")\n",
    "\n",
    "#crime_data_df_2015.show()\n",
    "\n",
    "race_csv = \"s3://initial-notebook-data-bucket-dblab-905418150721/RE_codes.csv\"\n",
    "race = spark.read.csv(race_csv, header=True, inferSchema=True)\n",
    "#race.show()\n",
    "\n",
    "#join top3 GDP per capita with crime data. Join is done with the geometry\n",
    "top3_crimes_df = (\n",
    "    crime_data_df_2015\n",
    "    .join(top_3, ST_Within(crime_data_df_2015.geom, top_3.geometry), \"inner\")\n",
    "    .groupBy(\"Vict Descent\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"#\")\n",
    "    )\n",
    ")\n",
    "#join previous Dataframe with a race Dataframe\n",
    "final_top_3_df = (\n",
    "    top3_crimes_df\n",
    "    .join(race, top3_crimes_df[\"`Vict Descent`\"] == race[\"`Vict Descent`\"], \"inner\")\n",
    "    .select(\n",
    "        race[\"`Vict Descent Full`\"].alias(\"Victim Descent\"),\n",
    "        \"#\"\n",
    "    )\n",
    "    .orderBy(col(\"#\").desc())\n",
    ")\n",
    "\n",
    "#final_top_3_df.show()\n",
    "\n",
    "bottom3_crimes_df = (\n",
    "    crime_data_df_2015\n",
    "    .join(bottom_3, ST_Within(crime_data_df_2015.geom, bottom_3.geometry), \"inner\")\n",
    "    .groupBy(\"Vict Descent\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"#\")\n",
    "    )\n",
    ")\n",
    "\n",
    "final_bottom_3_df = (\n",
    "    bottom3_crimes_df\n",
    "    .join(race, bottom3_crimes_df[\"`Vict Descent`\"] == race[\"`Vict Descent`\"], \"inner\")\n",
    "    .select(\n",
    "        race[\"`Vict Descent Full`\"].alias(\"Victim Descent\"),\n",
    "        \"#\"\n",
    "    )\n",
    "    .orderBy(col(\"#\").desc())\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Top 3:\")\n",
    "final_top_3_df.show()\n",
    "\n",
    "print(\"Bottom 3:\")\n",
    "final_bottom_3_df.show()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution Time: \", execution_time)\n",
    "\n",
    "conf = spark.sparkContext.getConf()\n",
    "\n",
    "log_data = {\n",
    "    \"spark_executor_instances\": conf.get(\"spark.executor.instances\"),\n",
    "    \"spark_executor_memory\": conf.get(\"spark.executor.memory\"),\n",
    "    \"spark_executor_cores\": conf.get(\"spark.executor.cores\"),\n",
    "    \"execution_time\": execution_time\n",
    "}\n",
    "\n",
    "log_df = spark.createDataFrame([log_data])\n",
    "\n",
    "s3_path = f\"s3://groups-bucket-dblab-905418150721/group45/q4/logfile.txt\"\n",
    "\n",
    "log_df.write.mode(\"append\").json(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2561ede-1ab8-4593-9811-b7a2127faad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------------+\n",
      "|spark_executor_cores|spark_executor_memory|    execution_time|\n",
      "+--------------------+---------------------+------------------+\n",
      "|                   4|                   8g|60.674782514572144|\n",
      "|                   2|                   4g| 70.12353825569153|\n",
      "|                   1|                   2g|  79.3983838558197|\n",
      "+--------------------+---------------------+------------------+"
     ]
    }
   ],
   "source": [
    "log_path = f\"s3://groups-bucket-dblab-905418150721/group45/q4/logfile.txt\"\n",
    "logs=spark.read.json(log_path)\n",
    "logs.select(\"spark_executor_cores\", \"spark_executor_memory\", \"execution_time\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc40eb-2c52-49ae-8fe7-de8ab9009b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
